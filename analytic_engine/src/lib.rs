// Copyright 2023 The CeresDB Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Analytic table engine implementations

#![feature(option_get_or_insert_default)]

mod compaction;
mod context;
mod engine;
mod instance;
mod manifest;
pub mod memtable;
mod payload;
pub mod prefetchable_stream;
pub mod row_iter;
mod sampler;
pub mod setup;
pub mod space;
pub mod sst;
pub mod table;
pub mod table_options;

pub mod table_meta_set_impl;
#[cfg(any(test, feature = "test"))]
pub mod tests;

use std::sync::{atomic::AtomicBool, Arc};

use manifest::details::Options as ManifestOptions;
use object_store::config::StorageOptions;
use serde::{Deserialize, Serialize};
use size_ext::ReadableSize;
use wal::config::StorageConfig;

use crate::sst::DynamicConfig as SstDynamicConfig;
pub use crate::{compaction::scheduler::SchedulerConfig, table_options::TableOptions};

/// Config of analytic engine
#[derive(Debug, Clone, Deserialize, Serialize)]
#[serde(default)]
pub struct Config {
    /// Storage options of the engine
    pub storage: StorageOptions,

    /// Batch size to read records from wal to replay
    pub replay_batch_size: usize,
    /// Batch size to replay tables
    pub max_replay_tables_per_batch: usize,

    /// Default options for table
    pub table_opts: TableOptions,

    pub compaction: SchedulerConfig,

    /// sst meta cache capacity
    pub sst_meta_cache_cap: Option<usize>,
    /// sst data cache capacity
    pub sst_data_cache_cap: Option<usize>,

    /// Manifest options
    pub manifest: ManifestOptions,

    /// The maximum rows in the write queue.
    pub max_rows_in_write_queue: usize,
    /// The maximum write buffer size used for single space.
    pub space_write_buffer_size: usize,
    /// The maximum size of all Write Buffers across all spaces.
    pub db_write_buffer_size: usize,
    /// The ratio of table's write buffer size to trigger preflush, and it
    /// should be in the range (0, 1].
    pub preflush_write_buffer_size_ratio: f32,
    pub enable_primary_key_sampling: bool,

    // Iterator scanning options
    /// Batch size for iterator.
    ///
    /// The `num_rows_per_row_group` in `table options` will be used if this is
    /// not set.
    pub scan_batch_size: Option<usize>,
    /// Max record batches in flight when scan
    pub scan_max_record_batches_in_flight: usize,
    /// Sst background reading parallelism
    pub sst_background_read_parallelism: usize,
    /// Reader options
    pub sst_reader_options: ReaderOptions,
    /// Number of streams to prefetch
    pub num_streams_to_prefetch: usize,
    /// Max buffer size for writing sst
    pub write_sst_max_buffer_size: ReadableSize,
    /// Max retry limit After flush failed
    pub max_retry_flush_limit: usize,
    /// Max bytes per write batch.
    ///
    /// If this is set, the atomicity of write request will be broken.
    pub max_bytes_per_write_batch: Option<ReadableSize>,

    /// Wal storage config
    ///
    /// Now, following three storages are supported:
    /// + RocksDB
    /// + OBKV
    /// + Kafka
    pub wal: StorageConfig,

    /// Recover mode
    ///
    /// + TableBased, tables on same shard will be recovered table by table.
    /// + ShardBased, tables on same shard will be recovered together.
    pub recover_mode: RecoverMode,

    pub remote_engine_client: remote_engine_client::config::Config,

    pub metrics: MetricsOptions,
}

#[derive(Debug, Default, Clone, Deserialize, Serialize)]
#[serde(default)]
pub struct ParquetReaderOptions {
    enable_page_filter: bool,
    enable_lazy_row_filter: bool,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
#[serde(tag = "type")]
pub enum ReaderOptions {
    Parquet(ParquetReaderOptions),
}

#[derive(Debug, Default, Clone, Deserialize, Serialize)]
#[serde(default)]
pub struct MetricsOptions {
    enable_table_level_metrics: bool,
}

#[derive(Debug, Clone, Copy, Deserialize, Serialize)]
pub enum RecoverMode {
    TableBased,
    ShardBased,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            storage: Default::default(),
            replay_batch_size: 500,
            max_replay_tables_per_batch: 64,
            table_opts: TableOptions::default(),
            compaction: SchedulerConfig::default(),
            sst_meta_cache_cap: Some(1000),
            sst_data_cache_cap: Some(1000),
            manifest: ManifestOptions::default(),
            max_rows_in_write_queue: 0,
            /// Zero means disabling this param, give a positive value to enable
            /// it.
            space_write_buffer_size: 0,
            /// Zero means disabling this param, give a positive value to enable
            /// it.
            db_write_buffer_size: 0,
            preflush_write_buffer_size_ratio: 0.75,
            enable_primary_key_sampling: false,
            scan_batch_size: None,
            sst_background_read_parallelism: 8,
            sst_reader_options: ReaderOptions::Parquet(ParquetReaderOptions::default()),
            num_streams_to_prefetch: 2,
            scan_max_record_batches_in_flight: 1024,
            write_sst_max_buffer_size: ReadableSize::mb(10),
            max_retry_flush_limit: 0,
            max_bytes_per_write_batch: None,
            wal: StorageConfig::RocksDB(Box::default()),
            remote_engine_client: remote_engine_client::config::Config::default(),
            recover_mode: RecoverMode::TableBased,
            metrics: MetricsOptions::default(),
        }
    }
}

/// Analytic dynamic config
#[derive(Debug, Default, Clone)]
pub struct DynamicConfig {
    pub sst: Arc<SstDynamicConfig>,
}

impl DynamicConfig {
    pub fn new(config: &Config) -> Self {
        let mut sst = SstDynamicConfig::default();
        let ReaderOptions::Parquet(opts) = &config.sst_reader_options;
        sst.parquet_enable_page_filter = AtomicBool::new(opts.enable_page_filter);
        sst.parquet_enable_lazy_row_filter = AtomicBool::new(opts.enable_lazy_row_filter);

        Self { sst: Arc::new(sst) }
    }
}
